#!/usr/bin/env python3
"""
ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€ HTML ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð° Telegram Ñ Ð¸Ð½ÑŠÐµÐºÑ†Ð¸ÐµÐ¹ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¹ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ñ‹Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹.
Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ñ‚ messages+audio.txt Ñ Ð²ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð½Ñ‹Ð¼ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼ Ð¸Ð· Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ñ‹Ñ….
"""

import sys
import re
from pathlib import Path

try:
    from bs4 import BeautifulSoup
except ImportError:
    print("ÐžÑˆÐ¸Ð±ÐºÐ°: ÐÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÑƒ BeautifulSoup4")
    print("Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ ÐµÑ‘ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¾Ð¹: pip install beautifulsoup4")
    sys.exit(1)


def load_transcriptions(transcriptions_dir):
    """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð²ÑÐµ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸, Ð¸Ð½Ð´ÐµÐºÑÐ¸Ñ€ÑƒÐµÑ‚ Ð¿Ð¾ Ð¸Ð¼ÐµÐ½Ð¸ Ñ„Ð°Ð¹Ð»Ð°"""
    transcriptions = {}

    for file_path in Path(transcriptions_dir).glob("audio_*.txt"):
        # Ð˜Ð¼Ñ Ð±ÐµÐ· .txt -> audio_5@07-04-2025_15-12-10
        key = file_path.stem
        text = extract_main_text(file_path)
        if text:
            transcriptions[key] = text
            print(f"  Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°: {file_path.name}")

    return transcriptions


def extract_main_text(file_path):
    """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸ (Ð±ÐµÐ· Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¼ÐµÑ‚Ð¾Ðº)"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # Ð¢ÐµÐºÑÑ‚ Ð¼ÐµÐ¶Ð´Ñƒ Ð¿ÐµÑ€Ð²Ñ‹Ð¼ Ð¸ Ð²Ñ‚Ð¾Ñ€Ñ‹Ð¼ Ð±Ð»Ð¾ÐºÐ¾Ð¼ ====
    parts = content.split('=' * 80)
    if len(parts) >= 2:
        return parts[1].strip()

    return None


def parse_message(msg_div, transcriptions):
    """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¸Ð· Ð¾Ð´Ð½Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ"""
    result = []

    is_service = 'service' in msg_div.get('class', [])

    if is_service:
        body = msg_div.find('div', class_='body')
        if body:
            text = body.get_text(strip=True)
            result.append(f"[{text}]")
        return result

    body = msg_div.find('div', class_='body')
    if not body:
        return result

    # Ð”Ð°Ñ‚Ð° Ð¸ Ð²Ñ€ÐµÐ¼Ñ
    date_elem = body.find('div', class_='date')
    if date_elem:
        date_text = date_elem.get('title', date_elem.get_text(strip=True))
        result.append(f"Ð”Ð°Ñ‚Ð°: {date_text}")

    # Ð˜Ð¼Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÐµÐ»Ñ
    from_name = body.find('div', class_='from_name')
    if from_name:
        result.append(f"ÐžÑ‚: {from_name.get_text(strip=True)}")

    # ÐžÑ‚Ð²ÐµÑ‚ Ð½Ð° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ
    reply_to = body.find('div', class_='reply_to')
    if reply_to:
        reply_text = reply_to.get_text(strip=True)
        result.append(f"â†©ï¸ {reply_text}")

    # ÐŸÐµÑ€ÐµÑÐ»Ð°Ð½Ð½Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ
    forwarded = body.find('div', class_='forwarded')
    if forwarded:
        result.append("--- ÐŸÐµÑ€ÐµÑÐ»Ð°Ð½Ð½Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ ---")
        fwd_from = forwarded.find('div', class_='from_name')
        if fwd_from:
            result.append(f"ÐžÑ‚: {fwd_from.get_text(strip=True)}")
        fwd_text = forwarded.find('div', class_='text')
        if fwd_text:
            text = process_text_element(fwd_text)
            result.append(f"Ð¢ÐµÐºÑÑ‚: {text}")

        # Ð“Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ Ð² Ð¿ÐµÑ€ÐµÑÐ»Ð°Ð½Ð½Ð¾Ð¼
        fwd_voice = forwarded.find('a', class_='media_voice_message')
        if fwd_voice:
            result.extend(process_voice_message(fwd_voice, transcriptions))

        result.append("--- ÐšÐ¾Ð½ÐµÑ† Ð¿ÐµÑ€ÐµÑÐ»Ð°Ð½Ð½Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ ---")

    # ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚
    text_elem = body.find('div', class_='text', recursive=False)
    if text_elem:
        text = process_text_element(text_elem)
        if text:
            result.append(f"Ð¢ÐµÐºÑÑ‚: {text}")

    # ÐœÐµÐ´Ð¸Ð°Ñ„Ð°Ð¹Ð»Ñ‹
    media_wrap = body.find('div', class_='media_wrap')
    if media_wrap:
        result.extend(process_media(media_wrap, transcriptions))

    # Ð ÐµÐ°ÐºÑ†Ð¸Ð¸
    reactions = body.find('span', class_='reactions')
    if reactions:
        reaction_list = []
        for reaction in reactions.find_all('span', class_='reaction'):
            emoji = reaction.find('span', class_='emoji')
            if emoji:
                emoji_text = emoji.get_text(strip=True)
                userpics = reaction.find('span', class_='userpics')
                count = len(userpics.find_all('div', class_='userpic')) if userpics else 1
                reaction_list.append(f"{emoji_text}Ã—{count}")
        if reaction_list:
            result.append(f"Ð ÐµÐ°ÐºÑ†Ð¸Ð¸: {', '.join(reaction_list)}")

    return result


def process_text_element(text_elem):
    """ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚, ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ"""
    for br in text_elem.find_all('br'):
        br.replace_with('\n')
    text = text_elem.get_text()
    lines = [line.strip() for line in text.split('\n')]
    return '\n'.join(lines).strip()


def process_voice_message(voice_elem, transcriptions):
    """ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ñ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸ÐµÐ¹"""
    result = []

    href = voice_elem.get('href', '')
    # voice_messages/audio_5@07-04-2025_15-12-10.ogg -> audio_5@07-04-2025_15-12-10
    filename = Path(href).stem

    duration_elem = voice_elem.find('div', class_='status')
    duration = duration_elem.get_text(strip=True) if duration_elem else ''

    result.append(f"ðŸŽ¤ Ð“Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ ({duration})")

    # Ð’ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸ÑŽ
    if filename in transcriptions:
        result.append(transcriptions[filename])

    return result


def process_media(media_wrap, transcriptions):
    """ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð¼ÐµÐ´Ð¸Ð°Ñ„Ð°Ð¹Ð»Ñ‹"""
    result = []

    # Ð“Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ
    voice = media_wrap.find('a', class_='media_voice_message')
    if voice:
        return process_voice_message(voice, transcriptions)

    # Ð¤Ð¾Ñ‚Ð¾
    photo = media_wrap.find('a', class_='photo_wrap')
    if photo:
        href = photo.get('href', '')
        result.append(f"ðŸ“· Ð¤Ð¾Ñ‚Ð¾: {href}")

    # Ð’Ð¸Ð´ÐµÐ¾
    video = media_wrap.find('a', class_='video_file_wrap')
    if video:
        href = video.get('href', '')
        video_title = media_wrap.find('div', class_='title')
        title = video_title.get_text(strip=True) if video_title else ''
        result.append(f"ðŸŽ¥ Ð’Ð¸Ð´ÐµÐ¾: {title} ({href})")

    # ÐÑƒÐ´Ð¸Ð¾
    audio = media_wrap.find('a', class_='audio_file')
    if audio:
        href = audio.get('href', '')
        audio_title = media_wrap.find('div', class_='title')
        title = audio_title.get_text(strip=True) if audio_title else ''
        duration = media_wrap.find('div', class_='duration')
        dur = duration.get_text(strip=True) if duration else ''
        result.append(f"ðŸŽµ ÐÑƒÐ´Ð¸Ð¾: {title} {dur} ({href})")

    # Ð¤Ð°Ð¹Ð»Ñ‹
    file_wrap = media_wrap.find('div', class_='file')
    if file_wrap:
        file_name = file_wrap.find('div', class_='name')
        file_size = file_wrap.find('div', class_='details')
        name = file_name.get_text(strip=True) if file_name else ''
        size = file_size.get_text(strip=True) if file_size else ''
        result.append(f"ðŸ“Ž Ð¤Ð°Ð¹Ð»: {name} ({size})")

    # Ð¡Ñ‚Ð¸ÐºÐµÑ€Ñ‹
    sticker = media_wrap.find('div', class_='sticker')
    if sticker:
        result.append("ðŸŽ¨ Ð¡Ñ‚Ð¸ÐºÐµÑ€")

    return result if result else ["ðŸ“Ž ÐœÐµÐ´Ð¸Ð°Ñ„Ð°Ð¹Ð»"]


def convert_with_transcriptions(html_path, transcriptions_dir, output_path):
    """ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ HTML Ð² Ñ‚ÐµÐºÑÑ‚ Ñ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸ÑÐ¼Ð¸ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ñ‹Ñ…"""

    print(f"Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÑŽ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸ Ð¸Ð·: {transcriptions_dir}")
    transcriptions = load_transcriptions(transcriptions_dir)
    print(f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¹: {len(transcriptions)}\n")

    print(f"Ð§Ð¸Ñ‚Ð°ÑŽ HTML: {html_path}")
    with open(html_path, 'r', encoding='utf-8') as f:
        html_content = f.read()

    soup = BeautifulSoup(html_content, 'html.parser')

    # Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ñ‡Ð°Ñ‚Ð°
    header = soup.find('div', class_='page_header')
    chat_title = "Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ñ‡Ð°Ñ‚Ð°"
    if header:
        title_elem = header.find('div', class_='text')
        if title_elem:
            chat_title = title_elem.get_text(strip=True)

    messages = soup.find_all('div', class_='message')
    print(f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹: {len(messages)}")

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write(f"{chat_title}\n")
        f.write("=" * 80 + "\n\n")

        for i, msg in enumerate(messages, 1):
            msg_lines = parse_message(msg, transcriptions)
            if msg_lines:
                msg_id = msg.get('id', '')

                if 'service' not in msg.get('class', []):
                    f.write(f"\n{'â”€' * 80}\n")
                    f.write(f"Ð¡Ð¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ ID: {msg_id}\n")
                    f.write('â”€' * 80 + "\n")

                for line in msg_lines:
                    f.write(line + "\n")

                f.write("\n")

            if i % 100 == 0:
                print(f"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾: {i}/{len(messages)}")

    print(f"\nâœ… Ð“Ð¾Ñ‚Ð¾Ð²Ð¾! Ð¤Ð°Ð¹Ð» ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½: {output_path}")
    print(f"Ð Ð°Ð·Ð¼ÐµÑ€: {output_path.stat().st_size / 1024:.2f} KB")


def main():
    base_dir = Path(__file__).parent.parent

    # ÐŸÑƒÑ‚Ð¸ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ
    html_path = base_dir / "ChatExport_2026-01-19" / "ChatExport_2026-01-19" / "messages.html"
    transcriptions_dir = base_dir / "data" / "transcriptions"
    output_path = base_dir / "data" / "messages+audio.txt"

    if len(sys.argv) >= 2:
        html_path = Path(sys.argv[1])
    if len(sys.argv) >= 3:
        transcriptions_dir = Path(sys.argv[2])
    if len(sys.argv) >= 4:
        output_path = Path(sys.argv[3])

    convert_with_transcriptions(html_path, transcriptions_dir, output_path)


if __name__ == '__main__':
    main()
